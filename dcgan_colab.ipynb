{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.augmentations.crops.transforms import CenterCrop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.activation import Tanh\n",
    "from torch.nn.modules.batchnorm import BatchNorm2d\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from dataset import WaterBodyGeneratorDataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import random\n",
    "\n",
    "\n",
    "#### GLOBALS\n",
    "nz= 100\n",
    "ngf = 256\n",
    "ndf = 256\n",
    "nc = 3\n",
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class GeneratorBlock(nn.Module):\n",
    "    \"\"\"Some Information about GeneratorBlock\"\"\"\n",
    "    def __init__(self, features_in, features_out, kernel_size, stride, padding):\n",
    "        super(GeneratorBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features_in, features_out, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(features_out),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Some Information about Generator\"\"\"\n",
    "    def __init__(self, latent_vector_size, channels_out):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.ModuleList()\n",
    "        self.main.append(GeneratorBlock(latent_vector_size, ngf * 32, kernel_size=4, stride=1, padding=0))\n",
    "        self.main.append(GeneratorBlock(ngf * 32, ngf * 16, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(GeneratorBlock(ngf * 16, ngf * 8, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(GeneratorBlock(ngf * 8, ngf * 4, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(GeneratorBlock(ngf * 4, ngf * 2, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(GeneratorBlock(ngf * 2, ngf, kernel_size=4, stride=2, padding=1))\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf, channels_out, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.main:\n",
    "            x = block(x)\n",
    "        #x = self.main(x)\n",
    "        x = self.last(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    \"\"\"Some Information about DiscriminatorBlock\"\"\"\n",
    "    def __init__(self, features_in, features_out, kernel_size, stride, padding):\n",
    "        super(DiscriminatorBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(features_in, features_out, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(features_out),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Some Information about Discriminator\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(input_size, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.main = nn.ModuleList()\n",
    "        self.main.append(DiscriminatorBlock(ndf, ndf * 2, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(DiscriminatorBlock(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(DiscriminatorBlock(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(DiscriminatorBlock(ndf * 8, ndf * 16, kernel_size=4, stride=2, padding=1))\n",
    "        self.main.append(DiscriminatorBlock(ndf * 16, ndf * 32, kernel_size=4, stride=2, padding=1))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(ndf * 32, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        for block in self.main:\n",
    "            x = block(x)\n",
    "        #x = self.main(x)\n",
    "        x = self.last(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WaterBodyGeneratorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about WaterBodyGeneratorDataset\"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(WaterBodyGeneratorDataset, self).__init__()\n",
    "\n",
    "        self._image_data = os.path.join(root, \"Images\")\n",
    "        self._filenames = os.listdir(self._image_data)\n",
    "        self.transform = transform\n",
    "        self._length = len(self._filenames)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self._image_data, self._filenames[index])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcgan_train(generator:nn.Module, discriminator:nn.Module, criterion, optimizerD, optimizerG, dataloader:torch.utils.data.DataLoader):\n",
    "    loop = tqdm(dataloader)\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(loop):\n",
    "\n",
    "        # Prepare real data\n",
    "        real_img = data[0].to(DEVICE)\n",
    "        batch_size = real_img.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=DEVICE)\n",
    "        \n",
    "\n",
    "        ##### TRAIN DISCRIMINATOR ON REAL IMAGES\n",
    "        discriminator.zero_grad()\n",
    "        output = discriminator(real_img).view(-1)\n",
    "\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # To print later\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ##### TRAIN DISCRIMINATOR ON FAKE IMAGES\n",
    "        noise = torch.randn(batch_size, 100, 1, 1, device=DEVICE)\n",
    "\n",
    "        fake = generator(noise)\n",
    "        label.fill_(fake_label)\n",
    "\n",
    "        output = discriminator(fake.detach()).view(-1)\n",
    "\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        # To print later\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        ##### TRAIN GENERATOR\n",
    "        generator.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = discriminator(fake).view(-1)\n",
    "\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        # To print later\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        #### Verbose\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Loss_D: {errD.item()} Loss_G: {errG.item()}   D(x): {D_x}   D(G(z)): {D_G_z1}   |    {D_G_z2}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_output(net, input):\n",
    "    with torch.no_grad():\n",
    "        out = net(input).detach().cpu()\n",
    "    return vutils.make_grid(out, padding=2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcgan import Generator, Discriminator, weights_init\n",
    "from train import dcgan_train, get_output\n",
    "from dataset import WaterBodyGeneratorDataset\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEC_SIZE = 100\n",
    "CHANNELS_OUT = 3\n",
    "DEVICE = \"cuda\"\n",
    "IMAGE_SIZE = (256,256)\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 2e-4\n",
    "BETA1 = 0.5\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(VEC_SIZE, CHANNELS_OUT).to(DEVICE)\n",
    "generator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(CHANNELS_OUT).to(DEVICE)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = A.Compose(\n",
    "    [\n",
    "        A.Resize(*IMAGE_SIZE),\n",
    "        A.Normalize(\n",
    "            mean = [0.0, 0.0, 0.0],\n",
    "            std=[1.0, 1.0, 1.0],\n",
    "            max_pixel_value=255.0),\n",
    "        A.pytorch.ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "tf2 = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean    = [0.5, 0.5, 0.5],\n",
    "            std     = [0.5, 0.5, 0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"D:/AI_ML/Kaggle/Water Bodies Dataset/\"\n",
    "dataset = WaterBodyGeneratorDataset(dataroot, tf2)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(BETA1, 0.999))\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "img_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_NOISE = torch.randn(IMAGE_SIZE[0], VEC_SIZE, 1, 1, device=DEVICE)\n",
    "for epoch in range(EPOCHS):\n",
    "    dcgan_train(generator=generator, discriminator=discriminator, criterion=criterion, optimizerD=optimizerD, optimizerG=optimizerG, dataloader=dataloader)\n",
    "    out = get_output(net=generator, input=FIXED_NOISE)\n",
    "    img_list.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ]
}